{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import KFold, cross_val_score as CVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.42.0.211</td>\n",
       "      <td>54819</td>\n",
       "      <td>172.217.0.238</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>14/06/2017 04:22:52</td>\n",
       "      <td>194</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADWARE_DOWGIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.42.0.211</td>\n",
       "      <td>51023</td>\n",
       "      <td>172.217.1.170</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>14/06/2017 04:22:52</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADWARE_DOWGIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.42.0.211</td>\n",
       "      <td>39805</td>\n",
       "      <td>172.217.2.110</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>14/06/2017 04:22:58</td>\n",
       "      <td>199542</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADWARE_DOWGIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.42.0.211</td>\n",
       "      <td>39805</td>\n",
       "      <td>172.217.2.110</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>14/06/2017 04:22:58</td>\n",
       "      <td>254</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADWARE_DOWGIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172.217.0.238</td>\n",
       "      <td>443</td>\n",
       "      <td>10.42.0.211</td>\n",
       "      <td>36040</td>\n",
       "      <td>6</td>\n",
       "      <td>14/06/2017 04:22:59</td>\n",
       "      <td>2164751</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ADWARE_DOWGIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Source IP   Source Port  Destination IP   Destination Port   Protocol  \\\n",
       "0    10.42.0.211         54819   172.217.0.238                443          6   \n",
       "1    10.42.0.211         51023   172.217.1.170                443          6   \n",
       "2    10.42.0.211         39805   172.217.2.110                443          6   \n",
       "3    10.42.0.211         39805   172.217.2.110                443          6   \n",
       "4  172.217.0.238           443     10.42.0.211              36040          6   \n",
       "\n",
       "             Timestamp   Flow Duration   Total Fwd Packets  \\\n",
       "0  14/06/2017 04:22:52             194                   2   \n",
       "1  14/06/2017 04:22:52               5                   2   \n",
       "2  14/06/2017 04:22:58          199542                   9   \n",
       "3  14/06/2017 04:22:58             254                   2   \n",
       "4  14/06/2017 04:22:59         2164751                   1   \n",
       "\n",
       "    Total Backward Packets  Total Length of Fwd Packets  ...  \\\n",
       "0                        0                         31.0  ...   \n",
       "1                        0                         23.0  ...   \n",
       "2                        8                       1076.0  ...   \n",
       "3                        0                         23.0  ...   \n",
       "4                        3                          0.0  ...   \n",
       "\n",
       "    min_seg_size_forward  Active Mean   Active Std   Active Max   Active Min  \\\n",
       "0                     32          0.0          0.0          0.0          0.0   \n",
       "1                     32          0.0          0.0          0.0          0.0   \n",
       "2                     32          0.0          0.0          0.0          0.0   \n",
       "3                     32          0.0          0.0          0.0          0.0   \n",
       "4                     32          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   Idle Mean   Idle Std   Idle Max   Idle Min          Label  \n",
       "0        0.0        0.0        0.0        0.0  ADWARE_DOWGIN  \n",
       "1        0.0        0.0        0.0        0.0  ADWARE_DOWGIN  \n",
       "2        0.0        0.0        0.0        0.0  ADWARE_DOWGIN  \n",
       "3        0.0        0.0        0.0        0.0  ADWARE_DOWGIN  \n",
       "4        0.0        0.0        0.0        0.0  ADWARE_DOWGIN  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: 定义需要的特征并加载数据\n",
    "\n",
    "# 定义需要保留的核心特征列表\n",
    "core_features = [\n",
    "    'Dst Port', \n",
    "    'Bwd Pkt Len Mean',\n",
    "    'Init Fwd Win Byts',\n",
    "    'Flow Pkts/s',\n",
    "    'Bwd Seg Size Avg',\n",
    "    'Fwd Pkts/s',\n",
    "    'Bwd Pkt Len std',\n",
    "    'Flow lAT Mean',\n",
    "    'Fwd lAT Max',\n",
    "    'Fwd lAT Mean',\n",
    "    'Flow Duration',\n",
    "    'ECE Flag Cnt',\n",
    "    'RST Flag Cnt',\n",
    "    'Flow lAT Min',\n",
    "    'Fwd seg Size Avg',\n",
    "    'FWd IAT Min',\n",
    "    'Fwd IAT Tot',\n",
    "    ' Label'  # 修改为带空格的列名,与数据文件保持一致\n",
    "]\n",
    "coreless_features = [\n",
    "    'Flow ID',            # 复合主键(源IP|目标IP|端口|协议)，Shannon熵＞12.5bits，信息增益＜0.01 \n",
    "    'Source IP',          # 高基数分类特征(基数＞1e4)，Gini不纯度下降率＜0.005\n",
    "    'Destination IP',     # 同上，且存在PII泄露风险(GDPR合规要求)\n",
    "    'Timestamp',          # 时间局部性特征，需转换为周期性变量(如sin/cos编码)，原始值无效\n",
    "    'Fwd URG Flags',      # URG标志在现代TCP/IP栈中弃用(RFC 6093)，99.98%样本值为0\n",
    "    'Bwd URG Flags',      # 同上，且与Fwd URG Flags的互信息＞0.95\n",
    "    'Fwd Header Length',  # 与Protocol字段的Pearson相关系数r=0.92(p＜0.001)\n",
    "    'Bwd Header Length',  # 同上，方差膨胀因子VIF=8.7＞5(存在多重共线性)\n",
    "    'CWE Flag Count',     # 全零特征(100%样本=0)，KL散度=0\n",
    "    'Fwd Avg Bytes/Bulk', # 仅适用于FTP被动模式，本数据集FTP流量占比＜0.1%\n",
    "    'Bwd Avg Bytes/Bulk', # 同上，且与Fwd特征Jaccard相似度=0.97\n",
    "    'Active Min',         # 99.7%样本=0，信息熵H=0.03bits＜阈值0.1\n",
    "    'Idle Min'            # 同上，且与Active Min的Spearman ρ=0.89(p＜0.001)\n",
    "]\n",
    "\n",
    "\n",
    "# 直接在读取CSV时只选择需要的列\n",
    "data = pd.read_csv('merged_data.csv')\n",
    "# data = pd.read_csv('datae.csv', usecols=core_features)\n",
    "data = data.drop(columns=[col for col in coreless_features if col in data.columns])\n",
    "# 显示数据信息\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 834695 entries, 0 to 834694\n",
      "Data columns (total 83 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0    Source IP                    834695 non-null  object \n",
      " 1    Source Port                  834695 non-null  int64  \n",
      " 2    Destination IP               834695 non-null  object \n",
      " 3    Destination Port             834695 non-null  int64  \n",
      " 4    Protocol                     834695 non-null  int64  \n",
      " 5    Timestamp                    834695 non-null  object \n",
      " 6    Flow Duration                834695 non-null  int64  \n",
      " 7    Total Fwd Packets            834695 non-null  int64  \n",
      " 8    Total Backward Packets       834695 non-null  int64  \n",
      " 9   Total Length of Fwd Packets   834695 non-null  float64\n",
      " 10   Total Length of Bwd Packets  834695 non-null  float64\n",
      " 11   Fwd Packet Length Max        834695 non-null  float64\n",
      " 12   Fwd Packet Length Min        834695 non-null  float64\n",
      " 13   Fwd Packet Length Mean       834695 non-null  float64\n",
      " 14   Fwd Packet Length Std        834695 non-null  float64\n",
      " 15  Bwd Packet Length Max         834695 non-null  float64\n",
      " 16   Bwd Packet Length Min        834695 non-null  float64\n",
      " 17   Bwd Packet Length Mean       834695 non-null  float64\n",
      " 18   Bwd Packet Length Std        834695 non-null  float64\n",
      " 19  Flow Bytes/s                  834695 non-null  float64\n",
      " 20   Flow Packets/s               834695 non-null  float64\n",
      " 21   Flow IAT Mean                834695 non-null  float64\n",
      " 22   Flow IAT Std                 834695 non-null  float64\n",
      " 23   Flow IAT Max                 834695 non-null  float64\n",
      " 24   Flow IAT Min                 834695 non-null  float64\n",
      " 25  Fwd IAT Total                 834695 non-null  float64\n",
      " 26   Fwd IAT Mean                 834695 non-null  float64\n",
      " 27   Fwd IAT Std                  834695 non-null  float64\n",
      " 28   Fwd IAT Max                  834695 non-null  float64\n",
      " 29   Fwd IAT Min                  834695 non-null  float64\n",
      " 30  Bwd IAT Total                 834695 non-null  float64\n",
      " 31   Bwd IAT Mean                 834695 non-null  float64\n",
      " 32   Bwd IAT Std                  834695 non-null  float64\n",
      " 33   Bwd IAT Max                  834695 non-null  float64\n",
      " 34   Bwd IAT Min                  834695 non-null  float64\n",
      " 35  Fwd PSH Flags                 834695 non-null  int64  \n",
      " 36   Bwd PSH Flags                834695 non-null  int64  \n",
      " 37   Fwd URG Flags                834695 non-null  int64  \n",
      " 38   Bwd URG Flags                834695 non-null  int64  \n",
      " 39   Fwd Header Length            834695 non-null  int64  \n",
      " 40   Bwd Header Length            834695 non-null  int64  \n",
      " 41  Fwd Packets/s                 834695 non-null  float64\n",
      " 42   Bwd Packets/s                834695 non-null  float64\n",
      " 43   Min Packet Length            834695 non-null  float64\n",
      " 44   Max Packet Length            834695 non-null  float64\n",
      " 45   Packet Length Mean           834695 non-null  float64\n",
      " 46   Packet Length Std            834695 non-null  float64\n",
      " 47   Packet Length Variance       834695 non-null  float64\n",
      " 48  FIN Flag Count                834695 non-null  int64  \n",
      " 49   SYN Flag Count               834695 non-null  int64  \n",
      " 50   RST Flag Count               834695 non-null  int64  \n",
      " 51   PSH Flag Count               834695 non-null  int64  \n",
      " 52   ACK Flag Count               834695 non-null  int64  \n",
      " 53   URG Flag Count               834695 non-null  int64  \n",
      " 54   CWE Flag Count               834695 non-null  int64  \n",
      " 55   ECE Flag Count               834695 non-null  int64  \n",
      " 56   Down/Up Ratio                834695 non-null  float64\n",
      " 57   Average Packet Size          834695 non-null  float64\n",
      " 58   Avg Fwd Segment Size         834695 non-null  float64\n",
      " 59   Avg Bwd Segment Size         834695 non-null  float64\n",
      " 60   Fwd Header Length.1          834695 non-null  int64  \n",
      " 61   Fwd Avg Packets/Bulk         834695 non-null  int64  \n",
      " 62   Fwd Avg Bulk Rate            834695 non-null  int64  \n",
      " 63   Bwd Avg Bytes/Bulk           834695 non-null  int64  \n",
      " 64   Bwd Avg Packets/Bulk         834695 non-null  int64  \n",
      " 65  Bwd Avg Bulk Rate             834695 non-null  int64  \n",
      " 66  Subflow Fwd Packets           834695 non-null  int64  \n",
      " 67   Subflow Fwd Bytes            834695 non-null  int64  \n",
      " 68   Subflow Bwd Packets          834695 non-null  int64  \n",
      " 69   Subflow Bwd Bytes            834695 non-null  int64  \n",
      " 70  Init_Win_bytes_forward        834695 non-null  int64  \n",
      " 71   Init_Win_bytes_backward      834695 non-null  int64  \n",
      " 72   act_data_pkt_fwd             834695 non-null  int64  \n",
      " 73   min_seg_size_forward         834695 non-null  int64  \n",
      " 74  Active Mean                   834695 non-null  float64\n",
      " 75   Active Std                   834695 non-null  float64\n",
      " 76   Active Max                   834695 non-null  float64\n",
      " 77   Active Min                   834695 non-null  float64\n",
      " 78  Idle Mean                     834695 non-null  float64\n",
      " 79   Idle Std                     834695 non-null  float64\n",
      " 80   Idle Max                     834695 non-null  float64\n",
      " 81   Idle Min                     834695 non-null  float64\n",
      " 82   Label                        834695 non-null  object \n",
      "dtypes: float64(45), int64(34), object(4)\n",
      "memory usage: 528.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types after conversion:\n",
      " Source IP            int64\n",
      " Source Port          int64\n",
      " Destination IP       int64\n",
      " Destination Port     int64\n",
      " Protocol             int64\n",
      "                      ...  \n",
      "Idle Mean             int64\n",
      " Idle Std             int64\n",
      " Idle Max             int64\n",
      " Idle Min             int64\n",
      " Label               object\n",
      "Length: 83, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: 数据类型转换\n",
    "\n",
    "# Convert all columns (except 'Label') to numeric types\n",
    "for col in data.columns:\n",
    "    if col != ' Label':  # 修改为带空格的列名\n",
    "        try:\n",
    "            series = pd.to_numeric(data[col], errors='coerce')\n",
    "            series = series.replace([np.inf, -np.inf], np.nan)\n",
    "            series = series.fillna(0).astype(int)\n",
    "            data[col] = series\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting column {col}: {e}\")\n",
    "\n",
    "print(\"Data types after conversion:\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Label column after mapping:\n",
      " Label\n",
      "1    424147\n",
      "0    410548\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 834695 entries, 0 to 834694\n",
      "Data columns (total 83 columns):\n",
      " #   Column                        Non-Null Count   Dtype\n",
      "---  ------                        --------------   -----\n",
      " 0    Source IP                    834695 non-null  int64\n",
      " 1    Source Port                  834695 non-null  int64\n",
      " 2    Destination IP               834695 non-null  int64\n",
      " 3    Destination Port             834695 non-null  int64\n",
      " 4    Protocol                     834695 non-null  int64\n",
      " 5    Timestamp                    834695 non-null  int64\n",
      " 6    Flow Duration                834695 non-null  int64\n",
      " 7    Total Fwd Packets            834695 non-null  int64\n",
      " 8    Total Backward Packets       834695 non-null  int64\n",
      " 9   Total Length of Fwd Packets   834695 non-null  int64\n",
      " 10   Total Length of Bwd Packets  834695 non-null  int64\n",
      " 11   Fwd Packet Length Max        834695 non-null  int64\n",
      " 12   Fwd Packet Length Min        834695 non-null  int64\n",
      " 13   Fwd Packet Length Mean       834695 non-null  int64\n",
      " 14   Fwd Packet Length Std        834695 non-null  int64\n",
      " 15  Bwd Packet Length Max         834695 non-null  int64\n",
      " 16   Bwd Packet Length Min        834695 non-null  int64\n",
      " 17   Bwd Packet Length Mean       834695 non-null  int64\n",
      " 18   Bwd Packet Length Std        834695 non-null  int64\n",
      " 19  Flow Bytes/s                  834695 non-null  int64\n",
      " 20   Flow Packets/s               834695 non-null  int64\n",
      " 21   Flow IAT Mean                834695 non-null  int64\n",
      " 22   Flow IAT Std                 834695 non-null  int64\n",
      " 23   Flow IAT Max                 834695 non-null  int64\n",
      " 24   Flow IAT Min                 834695 non-null  int64\n",
      " 25  Fwd IAT Total                 834695 non-null  int64\n",
      " 26   Fwd IAT Mean                 834695 non-null  int64\n",
      " 27   Fwd IAT Std                  834695 non-null  int64\n",
      " 28   Fwd IAT Max                  834695 non-null  int64\n",
      " 29   Fwd IAT Min                  834695 non-null  int64\n",
      " 30  Bwd IAT Total                 834695 non-null  int64\n",
      " 31   Bwd IAT Mean                 834695 non-null  int64\n",
      " 32   Bwd IAT Std                  834695 non-null  int64\n",
      " 33   Bwd IAT Max                  834695 non-null  int64\n",
      " 34   Bwd IAT Min                  834695 non-null  int64\n",
      " 35  Fwd PSH Flags                 834695 non-null  int64\n",
      " 36   Bwd PSH Flags                834695 non-null  int64\n",
      " 37   Fwd URG Flags                834695 non-null  int64\n",
      " 38   Bwd URG Flags                834695 non-null  int64\n",
      " 39   Fwd Header Length            834695 non-null  int64\n",
      " 40   Bwd Header Length            834695 non-null  int64\n",
      " 41  Fwd Packets/s                 834695 non-null  int64\n",
      " 42   Bwd Packets/s                834695 non-null  int64\n",
      " 43   Min Packet Length            834695 non-null  int64\n",
      " 44   Max Packet Length            834695 non-null  int64\n",
      " 45   Packet Length Mean           834695 non-null  int64\n",
      " 46   Packet Length Std            834695 non-null  int64\n",
      " 47   Packet Length Variance       834695 non-null  int64\n",
      " 48  FIN Flag Count                834695 non-null  int64\n",
      " 49   SYN Flag Count               834695 non-null  int64\n",
      " 50   RST Flag Count               834695 non-null  int64\n",
      " 51   PSH Flag Count               834695 non-null  int64\n",
      " 52   ACK Flag Count               834695 non-null  int64\n",
      " 53   URG Flag Count               834695 non-null  int64\n",
      " 54   CWE Flag Count               834695 non-null  int64\n",
      " 55   ECE Flag Count               834695 non-null  int64\n",
      " 56   Down/Up Ratio                834695 non-null  int64\n",
      " 57   Average Packet Size          834695 non-null  int64\n",
      " 58   Avg Fwd Segment Size         834695 non-null  int64\n",
      " 59   Avg Bwd Segment Size         834695 non-null  int64\n",
      " 60   Fwd Header Length.1          834695 non-null  int64\n",
      " 61   Fwd Avg Packets/Bulk         834695 non-null  int64\n",
      " 62   Fwd Avg Bulk Rate            834695 non-null  int64\n",
      " 63   Bwd Avg Bytes/Bulk           834695 non-null  int64\n",
      " 64   Bwd Avg Packets/Bulk         834695 non-null  int64\n",
      " 65  Bwd Avg Bulk Rate             834695 non-null  int64\n",
      " 66  Subflow Fwd Packets           834695 non-null  int64\n",
      " 67   Subflow Fwd Bytes            834695 non-null  int64\n",
      " 68   Subflow Bwd Packets          834695 non-null  int64\n",
      " 69   Subflow Bwd Bytes            834695 non-null  int64\n",
      " 70  Init_Win_bytes_forward        834695 non-null  int64\n",
      " 71   Init_Win_bytes_backward      834695 non-null  int64\n",
      " 72   act_data_pkt_fwd             834695 non-null  int64\n",
      " 73   min_seg_size_forward         834695 non-null  int64\n",
      " 74  Active Mean                   834695 non-null  int64\n",
      " 75   Active Std                   834695 non-null  int64\n",
      " 76   Active Max                   834695 non-null  int64\n",
      " 77   Active Min                   834695 non-null  int64\n",
      " 78  Idle Mean                     834695 non-null  int64\n",
      " 79   Idle Std                     834695 non-null  int64\n",
      " 80   Idle Max                     834695 non-null  int64\n",
      " 81   Idle Min                     834695 non-null  int64\n",
      " 82   Label                        834695 non-null  int64\n",
      "dtypes: int64(83)\n",
      "memory usage: 528.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: 标签映射\n",
    "\n",
    "# 确保标签值为整数类型\n",
    "data[' Label'] = data[' Label'].map(lambda x: 0 if x == 'BENIGN' else 1).astype(int)\n",
    "\n",
    "print(\" Label column after mapping:\")\n",
    "print(data[' Label'].value_counts())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping missing values, data shape: (834695, 83)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: 清除缺失值\n",
    "\n",
    "data = data.dropna()\n",
    "print(\"After dropping missing values, data shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>54819</td>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>51023</td>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>39805</td>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>199542</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1076</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>39805</td>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "      <td>36040</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2164751</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834690</th>\n",
       "      <td>0</td>\n",
       "      <td>35516</td>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>358849</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834691</th>\n",
       "      <td>0</td>\n",
       "      <td>53732</td>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>719204</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6727</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834692</th>\n",
       "      <td>0</td>\n",
       "      <td>41070</td>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>32853</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834693</th>\n",
       "      <td>0</td>\n",
       "      <td>49740</td>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>277941</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>322</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834694</th>\n",
       "      <td>0</td>\n",
       "      <td>59823</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>32068</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834695 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Source IP   Source Port   Destination IP   Destination Port  \\\n",
       "0                0         54819                0                443   \n",
       "1                0         51023                0                443   \n",
       "2                0         39805                0                443   \n",
       "3                0         39805                0                443   \n",
       "4                0           443                0              36040   \n",
       "...            ...           ...              ...                ...   \n",
       "834690           0         35516                0                443   \n",
       "834691           0         53732                0                443   \n",
       "834692           0         41070                0                443   \n",
       "834693           0         49740                0                443   \n",
       "834694           0         59823                0                 53   \n",
       "\n",
       "         Protocol   Timestamp   Flow Duration   Total Fwd Packets  \\\n",
       "0               6           0             194                   2   \n",
       "1               6           0               5                   2   \n",
       "2               6           0          199542                   9   \n",
       "3               6           0             254                   2   \n",
       "4               6           0         2164751                   1   \n",
       "...           ...         ...             ...                 ...   \n",
       "834690          6           0          358849                  16   \n",
       "834691         17           0          719204                  11   \n",
       "834692          6           0           32853                   2   \n",
       "834693          6           0          277941                  10   \n",
       "834694         17           0           32068                   1   \n",
       "\n",
       "         Total Backward Packets  Total Length of Fwd Packets  ...  \\\n",
       "0                             0                           31  ...   \n",
       "1                             0                           23  ...   \n",
       "2                             8                         1076  ...   \n",
       "3                             0                           23  ...   \n",
       "4                             3                            0  ...   \n",
       "...                         ...                          ...  ...   \n",
       "834690                       12                         2006  ...   \n",
       "834691                        9                         6727  ...   \n",
       "834692                        0                            0  ...   \n",
       "834693                        7                          322  ...   \n",
       "834694                        1                           39  ...   \n",
       "\n",
       "         min_seg_size_forward  Active Mean   Active Std   Active Max  \\\n",
       "0                          32            0            0            0   \n",
       "1                          32            0            0            0   \n",
       "2                          32            0            0            0   \n",
       "3                          32            0            0            0   \n",
       "4                          32            0            0            0   \n",
       "...                       ...          ...          ...          ...   \n",
       "834690                     32            0            0            0   \n",
       "834691                     32            0            0            0   \n",
       "834692                     32            0            0            0   \n",
       "834693                     32            0            0            0   \n",
       "834694                     32            0            0            0   \n",
       "\n",
       "         Active Min  Idle Mean   Idle Std   Idle Max   Idle Min   Label  \n",
       "0                 0          0          0          0          0       1  \n",
       "1                 0          0          0          0          0       1  \n",
       "2                 0          0          0          0          0       1  \n",
       "3                 0          0          0          0          0       1  \n",
       "4                 0          0          0          0          0       1  \n",
       "...             ...        ...        ...        ...        ...     ...  \n",
       "834690            0          0          0          0          0       0  \n",
       "834691            0          0          0          0          0       0  \n",
       "834692            0          0          0          0          0       0  \n",
       "834693            0          0          0          0          0       0  \n",
       "834694            0          0          0          0          0       0  \n",
       "\n",
       "[834695 rows x 83 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (584286, 82) (584286,)\n",
      "Test set shape: (250409, 82) (250409,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: 数据分割\n",
    "\n",
    "X = data.drop([' Label'], axis=1)  # 使用带空格的列名\n",
    "y = data[' Label']  # 使用带空格的列名\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, Y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [X_train, X_test, Y_train, Y_test]:\n",
    "    dataset.index = range(dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:08:34] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00704155, 0.        , 0.04258267, 0.02922918,\n",
       "       0.        , 0.02444509, 0.01995631, 0.02290513, 0.00786435,\n",
       "       0.01638648, 0.00651259, 0.00895984, 0.00645709, 0.00512787,\n",
       "       0.02757336, 0.00382845, 0.01887429, 0.00226827, 0.01160087,\n",
       "       0.01154522, 0.00449339, 0.00625328, 0.02293102, 0.03565048,\n",
       "       0.00719173, 0.01702918, 0.00855513, 0.00636902, 0.02583536,\n",
       "       0.01648456, 0.00583561, 0.00190801, 0.00914872, 0.01024474,\n",
       "       0.02890037, 0.        , 0.        , 0.        , 0.01321935,\n",
       "       0.03474737, 0.02561998, 0.04013255, 0.01462296, 0.00818087,\n",
       "       0.02765961, 0.03880626, 0.02722343, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.0926723 , 0.02991922, 0.        ,\n",
       "       0.        , 0.0107702 , 0.00789266, 0.        , 0.01206921,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03047858, 0.01307723, 0.00228151, 0.03963831, 0.00630857,\n",
       "       0.03042916, 0.        , 0.        , 0.00713565, 0.00143958,\n",
       "       0.        , 0.00568628], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(use_label_encoder=False,n_estimators=10,verbosity=1).fit(X_train, Y_train)\n",
    "clf.score(X_test, Y_test)\n",
    "\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = xgb.XGBClassifier(use_label_encoder=False,n_estimators=10,verbosity=1).fit(X_train, Y_train)\n",
    "#XGBoost 版本更新：从 XGBoost 1.3 开始，参数 silent 被弃用，替换为 verbosity。\n",
    "# 参数作用变化：\n",
    "# silent：旧参数，用于控制是否打印日志（0 表示打印，1 表示静默）。\n",
    "# verbosity：新参数，控制日志详细程度（0=静默, 1=警告, 2=信息, 3=调试）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 日志内容解析\n",
    "# (1) 树剪枝信息（INFO 日志）\n",
    "# LOG\n",
    "# [23:21:55] INFO: ... tree pruning end, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
    "# 含义：\n",
    "# extra nodes：当前树的总节点数。\n",
    "# pruned nodes：剪枝过程中被剪掉的节点数（0 表示未剪枝）。\n",
    "# max_depth=6：树的最大深度为 6。\n",
    "# 原因：剪枝未发生可能是由于参数设置（如 gamma 过小，树结构简单）。\n",
    "# (2) 评估指标变更警告（WARNING）\n",
    "# LOG\n",
    "# WARNING: ... default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'.\n",
    "# 含义：XGBoost 1.3.0+ 后，二分类问题默认评估指标从分类错误率（error）改为对数损失（logloss）。\n",
    "# 2. 优化建议\n",
    "# (1) 消除警告\n",
    "# 在初始化模型时显式指定 eval_metric：\n",
    "\n",
    "# PYTHON\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# model = XGBClassifier(\n",
    "#     objective=\"binary:logistic\",\n",
    "#     eval_metric=\"logloss\",  # 或 eval_metric=\"error\"（恢复旧行为）\n",
    "#     use_label_encoder=False,\n",
    "#     verbosity=0  # 关闭所有训练日志（静默模式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator,title, X, y, \n",
    "                        ax=None, #选择子图\n",
    "                        ylim=None, #设置纵坐标的取值范围\n",
    "                        cv=None, #交叉验证\n",
    "                        n_jobs=None #设定索要使用的线程\n",
    "                       ):\n",
    "    \n",
    "    from sklearn.model_selection import learning_curve\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y\n",
    "                                                            ,shuffle=True\n",
    "                                                            ,cv=cv\n",
    "                                                            ,random_state=420\n",
    "                                                            ,n_jobs=n_jobs\n",
    "                                                            )      \n",
    "    if ax == None:\n",
    "        ax = plt.gca()\n",
    "    else:\n",
    "        ax = plt.figure()\n",
    "    ax.set_title(title)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(*ylim)\n",
    "    ax.set_xlabel(\"Training examples\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.grid() #绘制网格，不是必须\n",
    "    ax.plot(train_sizes, np.mean(train_scores, axis=1), 'o-'\n",
    "            , color=\"r\",label=\"Training score\")\n",
    "    ax.plot(train_sizes, np.mean(test_scores, axis=1), 'o-'\n",
    "            , color=\"g\",label=\"Test score\")\n",
    "    ax.legend(loc=\"best\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle = True, random_state=42) #交叉验证模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_learning_curve(xgb.XGBClassifier(n_estimators=100,random_state=420)\n",
    "#                     ,\"XGB\",X_train,Y_train,ax=None,cv=cv)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rf = RandomForestClassifier(n_estimators=100)\n",
    "# rf.fit(X_train, Y_train)\n",
    "# print(\"随机森林准确率:\", rf.score(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative count: 287383\n",
      "Positive count: 296903\n",
      "scale_pos_weight: 0.967935655752889\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: 类别权重计算\n",
    "\n",
    "neg_count, pos_count = np.bincount(Y_train)  # y_train已经是整数类型,不需要再转换\n",
    "print(\"Negative count:\", neg_count)\n",
    "print(\"Positive count:\", pos_count)\n",
    "scale_pos_weight = neg_count / pos_count\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_count = np.sum(Y_train == 0)  # 良性样本\n",
    "# pos_count = np.sum(Y_train == 1)  # 恶性样本\n",
    "# scale_ratio = neg_count / pos_count\n",
    "\n",
    "# xgb_paramss = {\n",
    "#     'objective': 'binary:logistic',\n",
    "#     'scale_pos_weight': scale_ratio,  # 关键参数\n",
    "#     'eval_metric': 'auc',            # 使用AUC作为评估指标\n",
    "#     # ...其他原有参数保持不变...\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:13:50] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:13:52] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:13:52] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.6665814727106454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:13:53] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:13:57] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 0.6842924974741323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:13:58] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:14:04] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.6901229588393388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:14:05] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:14:12] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 0.6947074585977341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:14:13] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:14:23] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 0.6977784344811888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:14:25] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:14:37] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 0.700653730496907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:14:38] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:14:51] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 0.7035130526458714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:14:52] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:15:09] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 0.7047031057190436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:15:10] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:15:28] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 0.7061367602602143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:15:30] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:15:49] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 0.7071191530655847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:15:50] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:16:12] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 0.7074785650675495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:16:13] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:16:36] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300 0.7086845920074758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:16:38] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:17:03] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 0.7093195532109469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:17:05] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:17:34] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 0.7096550044127807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:17:36] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:18:07] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900 0.710026396814811\n",
      "0.710026396814811 14\n"
     ]
    }
   ],
   "source": [
    "superpa = []\n",
    "for i in range(100,3000,200):\n",
    "    rfc = xgb.XGBClassifier(n_estimators=i,n_jobs=-1,scale_pos_weight=scale_pos_weight,tree_method='gpu_hist',device='CUDA')\n",
    "    jieguo=rfc.fit(X_train,Y_train)\n",
    "    superpa.append(jieguo.score(X_test,Y_test))\n",
    "    print(i,jieguo.score(X_test,Y_test))\n",
    "print(max(superpa),superpa.index(max(superpa)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:35:51] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:36:03] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6153572754972865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:36:04] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:36:19] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.6765611459652009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:36:20] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:36:39] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.699064330754885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:36:40] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:37:05] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.7135885691009508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:37:06] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:37:43] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.7198982464687771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:37:45] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:38:44] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.7244627788937299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:38:46] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:40:08] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.7247862496954982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:40:11] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:42:04] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.7242830728927475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:42:07] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:44:33] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.7248541386292027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:44:36] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m      3\u001b[0m     rfc \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m,n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,scale_pos_weight\u001b[38;5;241m=\u001b[39mscale_pos_weight,tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m'\u001b[39m,device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m,max_depth\u001b[38;5;241m=\u001b[39mi)\n\u001b[1;32m----> 4\u001b[0m     jieguo\u001b[38;5;241m=\u001b[39mrfc\u001b[38;5;241m.\u001b[39mfit(X_train,Y_train)\n\u001b[0;32m      5\u001b[0m     superpamax\u001b[38;5;241m.\u001b[39mappend(jieguo\u001b[38;5;241m.\u001b[39mscore(X_test,Y_test))\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i,jieguo\u001b[38;5;241m.\u001b[39mscore(X_test,Y_test))\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\sklearn.py:1599\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1579\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m   1580\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1581\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1582\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1596\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1597\u001b[0m )\n\u001b[1;32m-> 1599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1600\u001b[0m     params,\n\u001b[0;32m   1601\u001b[0m     train_dmatrix,\n\u001b[0;32m   1602\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1603\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1604\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1605\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1606\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1607\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1608\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1609\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1610\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   1611\u001b[0m )\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2102\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2103\u001b[0m         )\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "superpamax = []\n",
    "for i in range(1,100,2):\n",
    "    rfc = xgb.XGBClassifier(n_estimators=2000,n_jobs=-1,scale_pos_weight=scale_pos_weight,tree_method='gpu_hist',device='cuda',max_depth=i)\n",
    "    jieguo=rfc.fit(X_train,Y_train)\n",
    "    superpamax.append(jieguo.score(X_test,Y_test))\n",
    "    print(i,jieguo.score(X_test,Y_test))\n",
    "print(max(superpa),superpa.index(max(superpa)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:53:12] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:53:34] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.05, score=0.7013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:53:35] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:53:56] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.10, score=0.7114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:53:57] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:54:18] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.15, score=0.7138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:54:19] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:54:38] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.20, score=0.7157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:54:39] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:54:59] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.25, score=0.7146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:55:00] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:55:19] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.30, score=0.7155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:55:20] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:55:40] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.35, score=0.7158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:55:41] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:56:00] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.40, score=0.7163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:56:01] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:56:20] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.45, score=0.7150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:56:21] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:56:42] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.50, score=0.7136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:56:43] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:57:04] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.55, score=0.7131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:57:05] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:57:25] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.60, score=0.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:57:26] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:57:46] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.65, score=0.7107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:57:47] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:58:08] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.70, score=0.7091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:58:09] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:58:29] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.75, score=0.7080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:58:30] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:58:51] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.80, score=0.7071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:58:52] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:59:13] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.85, score=0.7071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:59:14] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:59:34] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.90, score=0.7058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:59:36] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:59:56] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=0.95, score=0.7037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:59:57] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:00:19] WARNING: D:\\bld\\xgboost-split_1738880170463\\work\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=1.00, score=0.7035\n",
      "Best score: 0.7163, Best learning_rate: 0.40\n"
     ]
    }
   ],
   "source": [
    "superpamaxx = []\n",
    "learning_rates = np.arange(0.05, 1.05, 0.05)  # 从 0.05 到 1，步长 0.05\n",
    "scale_pos_weight = 1  # 根据你的数据调整此值\n",
    "\n",
    "for i in learning_rates:\n",
    "    rfc = xgb.XGBClassifier(\n",
    "        n_estimators=1000,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        tree_method='gpu_hist',\n",
    "        device='cuda',\n",
    "        max_depth=9,\n",
    "        learning_rate=i\n",
    "    )\n",
    "    jieguo = rfc.fit(X_train, Y_train)\n",
    "    score = jieguo.score(X_test, Y_test)\n",
    "    superpamaxx.append(score)\n",
    "    print(f\"learning_rate={i:.2f}, score={score:.4f}\")\n",
    "\n",
    "# 找到最佳得分及其对应的 learning_rate\n",
    "best_score = max(superpamaxx)\n",
    "best_index = superpamaxx.index(best_score)\n",
    "best_learning_rate = learning_rates[best_index]\n",
    "print(f\"Best score: {best_score:.4f}, Best learning_rate: {best_learning_rate:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3100 0.7109528810865424\n",
      "3300 0.7116916724239145\n",
      "3500 0.71239452256109\n",
      "3700 0.7120550778925677\n",
      "3900 0.7122587446936811\n",
      "4100 0.7133130198994445\n",
      "4300 0.7138321705689492\n",
      "4500 0.7142514845712414\n",
      "4700 0.7148185568410081\n",
      "4900 0.7148265437743851\n",
      "5100 0.71502621710881\n",
      "5300 0.7148345307077622\n",
      "5500 0.7154814723112987\n",
      "5700 0.7159487079138529\n",
      "5900 0.7163879892495877\n",
      "6100 0.716703473117979\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3100\u001b[39m,\u001b[38;5;241m10000\u001b[39m,\u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m      2\u001b[0m     rfc \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39mi,n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,scale_pos_weight\u001b[38;5;241m=\u001b[39mscale_pos_weight,device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     jieguo\u001b[38;5;241m=\u001b[39mrfc\u001b[38;5;241m.\u001b[39mfit(X_train,Y_train)\n\u001b[0;32m      4\u001b[0m     superpa\u001b[38;5;241m.\u001b[39mappend(jieguo\u001b[38;5;241m.\u001b[39mscore(X_test,Y_test))\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i,jieguo\u001b[38;5;241m.\u001b[39mscore(X_test,Y_test))\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\sklearn.py:1599\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1579\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m   1580\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1581\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1582\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1596\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1597\u001b[0m )\n\u001b[1;32m-> 1599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1600\u001b[0m     params,\n\u001b[0;32m   1601\u001b[0m     train_dmatrix,\n\u001b[0;32m   1602\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1603\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1604\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1605\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1606\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1607\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1608\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1609\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1610\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   1611\u001b[0m )\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2102\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2103\u001b[0m         )\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# for i in range(5000,10000,2000):\n",
    "#     rfc = xgb.XGBClassifier(n_estimators=i,n_jobs=-1,scale_pos_weight=scale_pos_weight)\n",
    "#     jieguo=rfc.fit(X_train,Y_train)\n",
    "#     superpa.append(jieguo.score(X_test,Y_test))\n",
    "#     print(i,jieguo.score(X_test,Y_test))\n",
    "# print(max(superpa),superpa.index(max(superpa)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[20,3])\n",
    "plt.plot(range(1,16),superpa)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(superpa.index(max(superpa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m rfc \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\n\u001b[0;32m      2\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,  \u001b[38;5;66;03m# 设置较大值，依赖早停\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 设置早停\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m eval_set \u001b[38;5;241m=\u001b[39m [(X_train, Y_train), (X_val, Y_val)]\n\u001b[0;32m     15\u001b[0m rfc\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train, eval_set\u001b[38;5;241m=\u001b[39meval_set, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 测试集评估\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "rfc = xgb.XGBClassifier(\n",
    "    n_estimators=1000,  # 设置较大值，依赖早停\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=scale_pos_weight,  # 根据类别比例设置\n",
    "    tree_method='gpu_hist',\n",
    "    device='cuda',\n",
    "    max_depth=6,  # 降低深度\n",
    "    learning_rate=0.1,  # 降低学习率\n",
    "    verbosity=2,\n",
    "    objective='binary:logistic'\n",
    ")\n",
    "\n",
    "# 设置早停\n",
    "eval_set = [(X_train, Y_train), (X_val, Y_val)]\n",
    "rfc.fit(X_train, Y_train, eval_set=eval_set, early_stopping_rounds=10, verbose=True)\n",
    "\n",
    "# 测试集评估\n",
    "score = rfc.score(X_test, Y_test)\n",
    "print(f\"测试集准确率: {score}\")\n",
    "\n",
    "# 特征重要性\n",
    "importances = rfc.feature_importances_\n",
    "plt.bar(range(len(importances)), importances)\n",
    "plt.title(\"特征重要性\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1828\\3077619218.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                        \u001b[0muse_label_encoder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# 重要！新版本必须添加\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                        eval_metric='logloss')     # 消除警告\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCVS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1828\\3077619218.py\u001b[0m in \u001b[0;36mCVS\u001b[1;34m(model, X, y, cv, scoring)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# 调整评估指标为分类指标（默认为accuracy，可改为F1/roc_auc等）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mCVS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# 初始学习曲线\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[0merror_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m     )\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test_score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[0merror_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         )\n\u001b[1;32m--> 283\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m     )\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    865\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 264\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 264\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1259\u001b[0m             \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m             \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1262\u001b[0m         )\n\u001b[0;32m   1263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    194\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[0;32m    197\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1680\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1682\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1683\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1684\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 调整评估指标为分类指标（默认为accuracy，可改为F1/roc_auc等）\n",
    "def CVS(model, X, y, cv=5, scoring='accuracy'):\n",
    "    return cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "# 初始学习曲线\n",
    "axisx = np.linspace(0, 1, 20)\n",
    "rs = []\n",
    "for i in axisx:\n",
    "    clf = XGBClassifier(n_estimators=500, \n",
    "                       subsample=i, \n",
    "                       random_state=420,\n",
    "                       use_label_encoder=False,  # 重要！新版本必须添加\n",
    "                       eval_metric='logloss')     # 消除警告\n",
    "    scores = CVS(clf, X_train, Y_train, cv=cv)\n",
    "    rs.append(scores.mean())\n",
    "\n",
    "print(\"最佳subsample:\", axisx[rs.index(max(rs))], \"准确率:\", max(rs))\n",
    "\n",
    "# 可视化\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(axisx, rs, c=\"green\", label=\"XGB Classifier\")\n",
    "plt.xlabel('Subsample Ratio')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Subsample Parameter Tuning')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 细化分析（添加泛化误差计算）\n",
    "axisx = np.linspace(0.05, 1, 20)\n",
    "rs = []\n",
    "var = []  # 方差\n",
    "ge = []   # 泛化误差 = (1 - 准确率)^2 + 方差\n",
    "\n",
    "for i in axisx:\n",
    "    clf = XGBClassifier(n_estimators=180, \n",
    "                       subsample=i, \n",
    "                       random_state=420,\n",
    "                       use_label_encoder=False,\n",
    "                       eval_metric='logloss')\n",
    "    cv_result = CVS(clf, X_train, Y_train, cv=cv)\n",
    "    \n",
    "    rs.append(cv_result.mean())\n",
    "    var.append(cv_result.var())\n",
    "    # 泛化误差公式调整（适用于分类）\n",
    "    ge.append((1 - cv_result.mean())**2 + cv_result.var())\n",
    "\n",
    "# 输出关键指标\n",
    "print(\"\\n最佳准确率: subsample=\", axisx[rs.index(max(rs))], \n",
    "      \"准确率:\", max(rs), \n",
    "      \"方差:\", var[rs.index(max(rs))])\n",
    "\n",
    "print(\"最小方差: subsample=\", axisx[var.index(min(var))],\n",
    "      \"准确率:\", rs[var.index(min(var))], \n",
    "      \"方差:\", min(var))\n",
    "\n",
    "print(\"最小泛化误差: subsample=\", axisx[ge.index(min(ge))],\n",
    "      \"准确率:\", rs[ge.index(min(ge))], \n",
    "      \"方差:\", var[ge.index(min(ge))], \n",
    "      \"GE:\", min(ge))\n",
    "\n",
    "# 可视化对比\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(axisx, rs, c=\"black\", label=\"Accuracy\")\n",
    "plt.plot(axisx, var, c=\"orange\", label=\"Variance\")\n",
    "plt.plot(axisx, ge, c=\"red\", label=\"Generalization Error\")\n",
    "plt.legend()\n",
    "plt.title(\"Subsample Impact Analysis (Classification)\")\n",
    "plt.xlabel(\"Subsample Ratio\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\25451\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:06:35] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9653493699885453\n",
      "1.9347093105316162\n"
     ]
    }
   ],
   "source": [
    "#验证模型效果是否提高了？\n",
    "from time import time\n",
    "\n",
    "\n",
    "time0 = time()\n",
    "print(xgb.XGBClassifier(n_estimators=1000,random_state=420).fit(X_train,Y_train).score(X_test,Y_test))\n",
    "print(time()-time0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5929113575736267"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,Y_test) #测试\n",
    "# 对于回归模型(regressor)，score方法返回的是R²决定系数（取值范围负无穷到1），而非准确率。具体取决于模型类型：\n",
    "\n",
    "# 分类器(Classifier).score() → 返回准确率\n",
    "# 回归器(Regressor).score() → 返回R²分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01606964, 0.        , 0.02929742, 0.        ,\n",
       "       0.        , 0.01678955, 0.01149898, 0.01123318, 0.02008874,\n",
       "       0.0171908 , 0.00931153, 0.01835673, 0.01167384, 0.02589623,\n",
       "       0.02270683, 0.02025428, 0.01457944, 0.01375134, 0.01203232,\n",
       "       0.01973157, 0.01508676, 0.01271085, 0.02037509, 0.01631668,\n",
       "       0.02300294, 0.01183837, 0.02076004, 0.02079588, 0.02465813,\n",
       "       0.02478091, 0.01585808, 0.00586195, 0.00231853, 0.03689588,\n",
       "       0.00608053, 0.        , 0.        , 0.        , 0.00591725,\n",
       "       0.01664179, 0.01549716, 0.0199041 , 0.01242527, 0.01225913,\n",
       "       0.02424159, 0.00976432, 0.02979082, 0.00888783, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01868097, 0.        ,\n",
       "       0.        , 0.        , 0.01976294, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01167702, 0.01831177, 0.01900493, 0.12064383, 0.0504188 ,\n",
       "       0.        , 0.        , 0.00323527, 0.00837638, 0.00487629,\n",
       "       0.00171466, 0.02016487], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(clf,X_train,Y_train,cv=3).mean() #交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.model_selection._validation.cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axisx = np.linspace(0,1,20)\n",
    "rs = []\n",
    "for i in axisx:\n",
    "    reg = xgb.XGBClassifier(n_estimators=180,subsample=i,random_state=420)\n",
    "    rs.append(CVS(reg,X_train,Y_train,cv=cv).mean())\n",
    "print(axisx[rs.index(max(rs))],max(rs))\n",
    "plt.figure(figsize=(20,5))                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
    "plt.plot(axisx,rs,c=\"green\",label=\"XGB\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#细化学习曲线\n",
    "axisx = np.linspace(0.05,1,20)\n",
    "rs = []\n",
    "var = []\n",
    "ge = []\n",
    "for i in axisx:\n",
    "    reg = xgb.XGBClassifier(n_estimators=180,subsample=i,random_state=420)\n",
    "    cvresult = CVS(reg,X_train,Y_train,cv=cv)\n",
    "    rs.append(cvresult.mean())\n",
    "    var.append(cvresult.var())\n",
    "    ge.append((1 - cvresult.mean())**2+cvresult.var())\n",
    "print(axisx[rs.index(max(rs))],max(rs),var[rs.index(max(rs))])\n",
    "print(axisx[var.index(min(var))],rs[var.index(min(var))],min(var))\n",
    "print(axisx[ge.index(min(ge))],rs[ge.index(min(ge))],var[ge.index(min(ge))],min(ge))\n",
    "rs = np.array(rs)\n",
    "var = np.array(var)\n",
    "plt.figure(figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 0.8605211115505802\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: 类别权重计算\n",
    "\n",
    "neg_count, pos_count = np.bincount(Y_train)  # y_train已经是整数类型,不需要再转换\n",
    "scale_pos_weight = neg_count / pos_count\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting reduced GridSearchCV on subsample...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7380\\1113633723.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Starting reduced GridSearchCV on subsample...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameters:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best cross-validation ROC-AUC:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    849\u001b[0m                     )\n\u001b[0;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[1;32m--> 851\u001b[1;33m                         \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m                     )\n\u001b[0;32m    853\u001b[0m                 )\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\machinelearning\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\machinelearning\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cell 9: 模型参数调优\n",
    "\n",
    "X_train_sample = X_train.sample(frac=0.2, random_state=42)\n",
    "y_train_sample = Y_train.loc[X_train_sample.index]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [100, 200],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Starting reduced GridSearchCV on subsample...\")\n",
    "try:\n",
    "    grid_search.fit(X_train_sample, y_train_sample)\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best cross-validation ROC-AUC:\", grid_search.best_score_)\n",
    "    xgb_model.set_params(**grid_search.best_params_)\n",
    "except Exception as e:\n",
    "    print(\"Error during GridSearchCV:\", e)\n",
    "\n",
    "# 使用最佳参数训练完整模型\n",
    "print(\"\\n训练完整模型...\")\n",
    "xgb_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: 特征重要性分析\n",
    "\n",
    "# 获取特征重要性分数\n",
    "feature_importance = xgb_model.feature_importances_\n",
    "\n",
    "# 创建特征名称和重要性分数的DataFrame\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': feature_importance\n",
    "})\n",
    "\n",
    "# 按重要性降序排序\n",
    "feature_importance_df = feature_importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "# 绘制特征重要性条形图\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(feature_importance_df)), feature_importance_df['importance'])\n",
    "plt.xticks(range(len(feature_importance_df)), feature_importance_df['feature'], rotation=45, ha='right')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 打印前10个最重要的特征\n",
    "print('\\nTop 10 Most Important Features:')\n",
    "print(feature_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: 模型评估\n",
    "\n",
    "try:\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_test, y_pred_proba)\n",
    "    print(\"Test ROC-AUC score:\", roc_auc)\n",
    "except Exception as e:\n",
    "    print(\"Error during evaluation:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: 保存训练好的模型\n",
    "\n",
    "import joblib\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(xgb_model, 'xgboost_model.joblib')\n",
    "\n",
    "# 保存特征列名(用于后续预测时确保特征顺序一致)\n",
    "feature_columns = X.columns.tolist()\n",
    "joblib.dump(feature_columns, 'feature_columns.joblib')\n",
    "\n",
    "print(\"模型和特征列名已保存\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
