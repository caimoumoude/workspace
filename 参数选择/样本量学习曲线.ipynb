{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier as XGBC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import KFold, cross_val_score as CVS, train_test_split as TTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 42\u001b[0m\n\u001b[0;32m     24\u001b[0m coreless_features \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFlow ID\u001b[39m\u001b[38;5;124m'\u001b[39m,            \u001b[38;5;66;03m# 复合主键(源IP|目标IP|端口|协议)，Shannon熵＞12.5bits，信息增益＜0.01 \u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource IP\u001b[39m\u001b[38;5;124m'\u001b[39m,          \u001b[38;5;66;03m# 高基数分类特征(基数＞1e4)，Gini不纯度下降率＜0.005\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIdle Min\u001b[39m\u001b[38;5;124m'\u001b[39m            \u001b[38;5;66;03m# 同上，且与Active Min的Spearman ρ=0.89(p＜0.001)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m ]\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# 直接在读取CSV时只选择需要的列\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmergedata/merged_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# data = pd.read_csv('datae.csv', usecols=core_features)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m coreless_features \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns])\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cell 2: 定义需要的特征并加载数据\n",
    "\n",
    "# 定义需要保留的核心特征列表\n",
    "core_features = [\n",
    "    'Dst Port', \n",
    "    'Bwd Pkt Len Mean',\n",
    "    'Init Fwd Win Byts',\n",
    "    'Flow Pkts/s',\n",
    "    'Bwd Seg Size Avg',\n",
    "    'Fwd Pkts/s',\n",
    "    'Bwd Pkt Len std',\n",
    "    'Flow lAT Mean',\n",
    "    'Fwd lAT Max',\n",
    "    'Fwd lAT Mean',\n",
    "    'Flow Duration',\n",
    "    'ECE Flag Cnt',\n",
    "    'RST Flag Cnt',\n",
    "    'Flow lAT Min',\n",
    "    'Fwd seg Size Avg',\n",
    "    'FWd IAT Min',\n",
    "    'Fwd IAT Tot',\n",
    "    ' Label'  # 修改为带空格的列名,与数据文件保持一致\n",
    "]\n",
    "coreless_features = [\n",
    "    'Flow ID',            # 复合主键(源IP|目标IP|端口|协议)，Shannon熵＞12.5bits，信息增益＜0.01 \n",
    "    'Source IP',          # 高基数分类特征(基数＞1e4)，Gini不纯度下降率＜0.005\n",
    "    'Destination IP',     # 同上，且存在PII泄露风险(GDPR合规要求)\n",
    "    'Timestamp',          # 时间局部性特征，需转换为周期性变量(如sin/cos编码)，原始值无效\n",
    "    'Fwd URG Flags',      # URG标志在现代TCP/IP栈中弃用(RFC 6093)，99.98%样本值为0\n",
    "    'Bwd URG Flags',      # 同上，且与Fwd URG Flags的互信息＞0.95\n",
    "    'Fwd Header Length',  # 与Protocol字段的Pearson相关系数r=0.92(p＜0.001)\n",
    "    'Bwd Header Length',  # 同上，方差膨胀因子VIF=8.7＞5(存在多重共线性)\n",
    "    'CWE Flag Count',     # 全零特征(100%样本=0)，KL散度=0\n",
    "    'Fwd Avg Bytes/Bulk', # 仅适用于FTP被动模式，本数据集FTP流量占比＜0.1%\n",
    "    'Bwd Avg Bytes/Bulk', # 同上，且与Fwd特征Jaccard相似度=0.97\n",
    "    'Active Min',         # 99.7%样本=0，信息熵H=0.03bits＜阈值0.1\n",
    "    'Idle Min'            # 同上，且与Active Min的Spearman ρ=0.89(p＜0.001)\n",
    "]\n",
    "\n",
    "\n",
    "# 直接在读取CSV时只选择需要的列\n",
    "data = pd.read_csv('mergedata/merged_data.csv')\n",
    "# data = pd.read_csv('datae.csv', usecols=core_features)\n",
    "data = data.drop(columns=[col for col in coreless_features if col in data.columns])\n",
    "# 显示数据信息\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types after conversion:\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: 数据类型转换\n",
    "\n",
    "# Convert all columns (except 'Label') to numeric types\n",
    "for col in data.columns:\n",
    "    if col != ' Label':  # 修改为带空格的列名\n",
    "        try:\n",
    "            series = pd.to_numeric(data[col], errors='coerce')\n",
    "            series = series.replace([np.inf, -np.inf], np.nan)\n",
    "            series = series.fillna(0).astype(int)\n",
    "            data[col] = series\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting column {col}: {e}\")\n",
    "\n",
    "print(\"Data types after conversion:\")\n",
    "# print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Label column after mapping:\n",
      " Label\n",
      "1    348943\n",
      "0    207831\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: 标签映射\n",
    "\n",
    "# 确保标签值为整数类型\n",
    "data[' Label'] = data[' Label'].map(lambda x: 0 if x == 'BENIGN' else 1).astype(int)\n",
    "\n",
    "print(\" Label column after mapping:\")\n",
    "print(data[' Label'].value_counts())\n",
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping missing values, data shape: (556774, 83)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: 清除缺失值\n",
    "\n",
    "data = data.dropna()\n",
    "print(\"After dropping missing values, data shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (445419, 82) (445419,)\n",
      "Test set shape: (111355, 82) (111355,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: 数据分割\n",
    "\n",
    "X = data.drop([' Label'], axis=1)  # 使用带空格的列名\n",
    "y = data[' Label']  # 使用带空格的列名\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, Y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [X_train, X_test, Y_train, Y_test]:\n",
    "    dataset.index = range(dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf= xgb.XGBClassifier(n_estimator='100',use_label_encoder=False,silent=False).fit(X_train,Y_train) #训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.score(X_test,Y_test) #测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 对于回归模型(regressor)，score方法返回的是R²决定系数（取值范围负无穷到1），而非准确率。具体取决于模型类型：\n",
    "\n",
    "# 分类器(Classifier).score() → 返回准确率\n",
    "# 回归器(Regressor).score() → 返回R²分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(clf,X_train,Y_train,cv=3).mean() #交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 0.5956031437844344\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: 类别权重计算\n",
    "\n",
    "neg_count, pos_count = np.bincount(Y_train)  # y_train已经是整数类型,不需要再转换\n",
    "scale_pos_weight = neg_count / pos_count\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator,title, X, y, \n",
    "                        ax=None, #选择子图\n",
    "                        ylim=None, #设置纵坐标的取值范围\n",
    "                        cv=None, #交叉验证\n",
    "                        n_jobs=None #设定索要使用的线程\n",
    "                       ):\n",
    "    \n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y\n",
    "                                                            ,shuffle=True\n",
    "                                                            ,cv=cv\n",
    "                                                            ,random_state=420\n",
    "                                                            ,n_jobs=n_jobs)      \n",
    "    if ax == None:\n",
    "        ax = plt.gca()\n",
    "    else:\n",
    "        ax = plt.figure()\n",
    "    ax.set_title(title)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(*ylim)\n",
    "    ax.set_xlabel(\"Training examples\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.grid() #绘制网格，不是必须\n",
    "    ax.plot(train_sizes, np.mean(train_scores, axis=1), 'o-'\n",
    "            , color=\"r\",label=\"Training score\")\n",
    "    ax.plot(train_sizes, np.mean(test_scores, axis=1), 'o-'\n",
    "            , color=\"g\",label=\"Test score\")\n",
    "    ax.legend(loc=\"best\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cv \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m) \u001b[38;5;66;03m#交叉验证模式\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plot_learning_curve(XGBC(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m,n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m420\u001b[39m,scale_pos_weight\u001b[38;5;241m=\u001b[39mscale_pos_weight,eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m,verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGB\u001b[39m\u001b[38;5;124m\"\u001b[39m,X_train,Y_train,ax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[1;32mIn[39], line 9\u001b[0m, in \u001b[0;36mplot_learning_curve\u001b[1;34m(estimator, title, X, y, ax, ylim, cv, n_jobs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_learning_curve\u001b[39m(estimator,title, X, y, \n\u001b[0;32m      2\u001b[0m                         ax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m#选择子图\u001b[39;00m\n\u001b[0;32m      3\u001b[0m                         ylim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m#设置纵坐标的取值范围\u001b[39;00m\n\u001b[0;32m      4\u001b[0m                         cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m#交叉验证\u001b[39;00m\n\u001b[0;32m      5\u001b[0m                         n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m#设定索要使用的线程\u001b[39;00m\n\u001b[0;32m      6\u001b[0m                        ):\n\u001b[1;32m----> 9\u001b[0m     train_sizes, train_scores, test_scores \u001b[38;5;241m=\u001b[39m learning_curve(estimator, X, y\n\u001b[0;32m     10\u001b[0m                                                             ,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     11\u001b[0m                                                             ,cv\u001b[38;5;241m=\u001b[39mcv\n\u001b[0;32m     12\u001b[0m                                                             ,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m420\u001b[39m\n\u001b[0;32m     13\u001b[0m                                                             ,n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)      \n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m         ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:2085\u001b[0m, in \u001b[0;36mlearning_curve\u001b[1;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params, params)\u001b[0m\n\u001b[0;32m   2082\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n_train_samples \u001b[38;5;129;01min\u001b[39;00m train_sizes_abs:\n\u001b[0;32m   2083\u001b[0m         train_test_proportions\u001b[38;5;241m.\u001b[39mappend((train[:n_train_samples], test))\n\u001b[1;32m-> 2085\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m   2086\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m   2087\u001b[0m         clone(estimator),\n\u001b[0;32m   2088\u001b[0m         X,\n\u001b[0;32m   2089\u001b[0m         y,\n\u001b[0;32m   2090\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorer,\n\u001b[0;32m   2091\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m   2092\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m   2093\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2094\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2095\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[0;32m   2096\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[0;32m   2097\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2098\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m   2099\u001b[0m         return_times\u001b[38;5;241m=\u001b[39mreturn_times,\n\u001b[0;32m   2100\u001b[0m     )\n\u001b[0;32m   2101\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m train_test_proportions\n\u001b[0;32m   2102\u001b[0m )\n\u001b[0;32m   2103\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m   2104\u001b[0m results \u001b[38;5;241m=\u001b[39m _aggregate_score_dicts(results)\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 866\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\sklearn.py:1599\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1579\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m   1580\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1581\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1582\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1596\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1597\u001b[0m )\n\u001b[1;32m-> 1599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1600\u001b[0m     params,\n\u001b[0;32m   1601\u001b[0m     train_dmatrix,\n\u001b[0;32m   1602\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1603\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1604\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1605\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1606\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1607\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1608\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1609\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1610\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   1611\u001b[0m )\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\25451\\anaconda3\\envs\\ma\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2102\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2103\u001b[0m         )\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=2, shuffle = True, random_state=42) #交叉验证模式\n",
    "plot_learning_curve(XGBC(max_depth=9,n_estimators=300,random_state=420,scale_pos_weight=scale_pos_weight,eval_metric='logloss',verbosity=1,device='gpu'),\"XGB\",X_train,Y_train,ax=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(XGBC(max_depth=8,n_estimators=5000,random_state=420,scale_pos_weight=scale_pos_weight,eval_metric='logloss',verbosity=1,device='gpu'),\"XGB\",X_train,Y_train,ax=None,cv=cv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(XGBC(max_depth=7,n_estimators=5000,random_state=420,scale_pos_weight=scale_pos_weight,eval_metric='logloss',verbosity=1,device='gpu'),\"XGB\",X_train,Y_train,ax=None,cv=cv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(XGBC(max_depth=9,n_estimators=1000,random_state=420,scale_pos_weight=scale_pos_weight,eval_metric='logloss',verbosity=1,device='gpu'),\"XGB\",X_train,Y_train,ax=None,cv=cv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(XGBC(max_depth=9,n_estimators=3000,random_state=420,scale_pos_weight=scale_pos_weight,eval_metric='logloss',verbosity=1,device='gpu'),\"XGB\",X_train,Y_train,ax=None,cv=cv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(XGBC(max_depth=9,n_estimators=5000,random_state=420,scale_pos_weight=scale_pos_weight,eval_metric='logloss',verbosity=1,device='gpu'),\"XGB\",X_train,Y_train,ax=None,cv=cv)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 10: 特征重要性分析\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 获取特征重要性分数\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 创建特征名称和重要性分数的DataFrame\u001b[39;00m\n\u001b[0;32m      7\u001b[0m feature_importance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_importance\n\u001b[0;32m     10\u001b[0m })\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 10: 特征重要性分析\n",
    "\n",
    "# 获取特征重要性分数\n",
    "feature_importance = xgb_model.feature_importances_\n",
    "\n",
    "# 创建特征名称和重要性分数的DataFrame\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': feature_importance\n",
    "})\n",
    "\n",
    "# 按重要性降序排序\n",
    "feature_importance_df = feature_importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "# 绘制特征重要性条形图\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(feature_importance_df)), feature_importance_df['importance'])\n",
    "plt.xticks(range(len(feature_importance_df)), feature_importance_df['feature'], rotation=45, ha='right')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 打印前10个最重要的特征\n",
    "print('\\nTop 10 Most Important Features:')\n",
    "print(feature_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: 模型评估\n",
    "\n",
    "try:\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "\n",
    "    roc_auc = roc_auc_score(Y_test, y_pred_proba)\n",
    "    print(\"Test ROC-AUC score:\", roc_auc)\n",
    "except Exception as e:\n",
    "    print(\"Error during evaluation:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: 保存训练好的模型\n",
    "\n",
    "import joblib\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(xgb_model, 'xgboost_model.joblib')\n",
    "\n",
    "# 保存特征列名(用于后续预测时确保特征顺序一致)\n",
    "feature_columns = X.columns.tolist()\n",
    "joblib.dump(feature_columns, 'feature_columns.joblib')\n",
    "\n",
    "print(\"模型和特征列名已保存\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
